<html>
<head>
    <meta charset="UTF-8">
    <title>Binary data types</title>
    <link rel="stylesheet" type="text/css" media="all" href="styles.css" />
    <link href="https://fonts.googleapis.com/css?family=Unica+One|Noticia+Text:400,400i,700,700i|Fira+Mono:400,700,&amp;subset=latin-ext" rel="stylesheet">
    <link rel="stylesheet" href="highlight/styles/github.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="highlight/highlight.pack.js"></script>
    <script>
        $(document).ready(function()
        {
          $('code.x86asm').each(function(i, block)
          {
            hljs.highlightBlock(block);
          });
          $('code.swift').each(function(i, block)
          {
            hljs.highlightBlock(block);
          });
          $('pre.x86asm').each(function(i, block)
          {
            hljs.highlightBlock(block);
          });
        });
    </script>
</head>
<body>
    <a class="nav-triangle-left" href="chapter0.html"><div>Prev</div></a>
    <a class="nav-triangle-right" href="chapter2.html"><div>Next</div></a>

    <div class="content-container">
        <div class="content">
            <div class="chapter-header"><div class="chapter-number">1</div><h1>Binary data types</h1></div><p><keyword>Bits</keyword> form the basis of all contemporary computing. Computers run on bits because bits are the smallest possible unit of information — a yes or a no, or a 0 or a 1. (Someday, we’ll have quantum computers that run on “qubits” but we’re only going to talk about ordinary bits here.)</p><p>We can use bits as <keyword>digits</keyword> to form a number system. This number system is a <keyword>binary</keyword> number system, since each binary digit can only take two possible values. (The word <em>bit</em> is actually short for <em><strong>b</strong>inary <strong>d</strong>igit</em>.) In contrast, our human number system is a <keyword>decimal</keyword> number system, made out of decimal digits that can take ten possible values, 0 through 9.</p><h2>Bits can represent whole numbers</h2><p>Just as we can string together multiple decimal digits to represent numbers bigger than 9, we can string together multiple bits to represent numbers bigger than 1. You might remember from elementary school that digits have <keyword>place values</keyword> depending on their positions in the sequence. In decimal, the place values are ones, tens, hundreds, thousands, and so on. In binary, the place values are ones, twos, fours, eights, sixteens, and so on.</p><p>The digit with the smallest place value is called the <keyword>least significant digit</keyword>, and the digit with the largest place value is called the <keyword>most significant digit</keyword>. In English, we usually write the least significant digit on the right and the most significant digit on the left.</p><table class="place-table"><tr><td>Thousands</td> <td>Hundreds</td> <td>Tens</td> <td>Ones</td> <td>Total</td></tr>
<tr><td>1</td> <td>9</td> <td>8</td> <td>9</td> <td>= 1000 + 900 + 80 + 9</td></tr>
<tr><td colspan="4"></td> <td>= 1989</td></tr></table><table class="place-table"><tr><td>Eights</td> <td>Fours</td> <td>Twos</td> <td>Ones</td> <td>Total</td></tr>
<tr><td>1</td> <td>1</td> <td>0</td> <td>1</td> <td>= 8 + 4 + 1</td></tr>
<tr><td colspan="4"></td> <td>= 13</td></tr></table><p>The largest number you can count up to with <simple-math><var>n</var></simple-math> unsigned decimal digits is <simple-math>10<sup><var>n</var></sup> − 1</simple-math>. If you have three decimal digits, you can count up to <simple-math>10<sup>3</sup> − 1</simple-math>, or 999. Similarly, if you have <simple-math><var>n</var></simple-math> binary digits, you can count all the way up to <simple-math>2<sup><var>n</var></sup> − 1</simple-math>. So if you have three bits, you can count all the way up to <simple-math>2<sup>3</sup> − 1</simple-math>, or 7.</p><p>Almost all computers today store bits in groups of eight, called <keyword>bytes</keyword>. The exceptions are too few to be within the scope of this book. A byte can take <simple-math>2<sup>8</sup></simple-math> possible values. This means if you start from 0 (<code>0000,0000</code>), you can count all the way up to <simple-math>2<sup>8</sup> − 1</simple-math>, or 255 (<code>1111,1111</code>). We define this as the <keyword>unsigned integer interpretation</keyword> of a byte value.</p><h2>Binary addition</h2><p>Binary addition works a lot like decimal addition. You add up the bits in each place value from least to most significant, carrying the 1 when appropriate.</p><div class="centered-container"><ascii-figure>  1 1<br/>  0 1 1 0 = 6<br/>+ 0 0 1 1 = 3<br/>—————————<br/>  1 0 0 1 = 9</ascii-figure></div><p>If a 1 gets carried off of the last bit, the result will have one more bit than either of the inputs. Computers, however, work on a fixed number of bits. If you carry a 1 off of the last bit in an 8-bit addition, that carried 1 is lost, effectively subtracting 256 from the result.</p><div class="centered-container"><ascii-figure>  1 1 1 1 1 1 1 1<br/>    1 1 1 1 1 1 1 1 = 255<br/>+   0 0 0 0 0 0 0 1 =   1<br/>———————————————————<br/>  _ 0 0 0 0 0 0 0 0 =   0???</ascii-figure></div><aside>A few languages like Java, Ruby, and Python automatically extend their integer types at run-time when they detect overflow, a lot like how you would use extra space on the the paper to write down the carry-out digit when doing addition by hand. These integer types are called <keyword>bignums</keyword> or <keyword>big integers</keyword>. These languages sacrifice speed so that you don’t have to worry about integer overflow. Swift makes the opposite tradeoff, making Swift programs fast, but susceptible to integer overflow.</aside><p>This means if you keep incrementing an unsigned byte value, it will eventually wrap around and start counting back up from zero. A good physical anology is an analog car odometer — once it hits 999,999, the next number it shows is 000,000. This phenomenon is called <keyword>integer overflow</keyword>.</p><h2>Integer overflow gives us subtraction</h2><p>We could try and do binary subtraction just like we did binary addition.</p><div class="centered-container"><ascii-figure>             −1 10<br/>  0 0 0 1 0 0 1 0 = 18<br/>− 0 0 0 0 0 0 0 1 =  1<br/>—————————————————<br/>  0 0 0 1 0 0 0 1 = 17</ascii-figure></div><p>Subtraction is a lot harder than addition, mostly because you have to borrow, though in principle, you <em>could</em> build a CPU circuit that performs subtraction just like the one that performs addition. But it turns out there’s an easier way.</p><p>Imagine that you have space for three decimal digits — you can count from 0 all the way to 999. One way to subtract 1 from an arbitrary three-digit decimal number, <em>without actually doing subtraction</em>, is to <em>add</em> 999 to it. For example, if you had the number 25, adding 999 to it would give you 1024. But since you don’t have a thousands place, you just end up with 24.</p><p>This works because adding 999 is the same as adding 1000 and subtracting 1. Integer overflow then subtracts 1000 from the total, so in the end you are effectively subtracting 1. Similarly, you can subtract 2 by adding 998, 3 by adding 997, and so forth.</p><div class="centered-container"><ascii-figure>   NNN + 999<br/>=  NNN + 1000 − 1<br/>= 1NNN − 1<br/>→  NNN - 1 </ascii-figure></div><div class="centered-container"><ascii-figure>   NNN + 998<br/>=  NNN + 1000 − 2<br/>= 1NNN − 2<br/>→  NNN - 2 </ascii-figure></div><div class="centered-container"><ascii-figure>   NNN + 997<br/>=  NNN + 1000 − 3<br/>= 1NNN − 3<br/>→  NNN - 3 </ascii-figure></div><p>In other words, to subtract a number <simple-math><var>n</var></simple-math>, you add <simple-math><var>n</var></simple-math> less than the <em>smallest number not representable</em> by the digits you have. Remember, this number is equal to <simple-math><var>base</var> <sup><var>digits</var></sup></simple-math>. So for an 8-bit value, you subtract 1 by adding 255. You subtract 2 by adding 254, and so forth. You can use addition to get subtraction for free.</p><h2>Subtraction gives us negative numbers</h2><aside>This should come naturally to any of you who know <keyword>modular arithmetic</keyword>. If you haven’t figured it out already, the <keyword>modulus</keyword> of a binary number with <simple-math><var>n</var></simple-math> bits is always <simple-math>2<sup><var>n</var></sup></simple-math>.</aside><p>Mind you that subtracting <simple-math><var>n</var></simple-math> is the same thing as adding <simple-math>−<var>n</var></simple-math>. And since we just established that subtracting <simple-math><var>n</var></simple-math> is also the same thing as adding <simple-math><var>base</var> <sup><var>digits</var></sup> − <var>n</var></simple-math>, that implies that <simple-math>−<var>n</var> = <var>base</var> <sup><var>digits</var></sup> − <var>n</var></simple-math>. Now we have <em>two</em> ways of interpreting any binary number. We can interpret the 8 bit number <code>0101,1001</code> as the positive number <simple-math>89</simple-math>, or we can interpret it as the negative number <simple-math>89 − 256 = −167</simple-math>.</p><h2>Negate numbers using the two’s complement</h2><aside>Don’t confuse the negative of a number with the <em>negative interpretation</em> of a number. The latter always has the exact same bit pattern as the number because it’s just another way of reading it. The negative of a number has a completely different bit pattern.</aside><p>Subtraction-by-addition isn’t very useful if you don’t have an easy way of negating a number. Let’s go back to the three-digit decimal example. To get the negative of a three-digit decimal number <simple-math><var>n</var></simple-math>, you have to compute <simple-math>1000 − <var>n</var></simple-math>. This quantity is called the <keyword>ten’s complement</keyword> of the number. But doing <simple-math>1000 − <var>n</var></simple-math> directly is hard because you have to borrow all the way out to the hundreds place. So instead, we do <simple-math>999 − <var>n</var></simple-math>, and then add 1 later.</p><div class="centered-container"><ascii-figure>  9 9 9<br/>− 7 8 9<br/>———————<br/>  2 1 0 = nines complement<br/>+     1<br/>———————<br/>  2 1 1 = ten’s complement</ascii-figure></div><aside>Don’t confuse the nines complement with the <em>nine’s</em> complement. (There’s an apostrophe.) The nines complement (without the apostrophe) is a digit-wise operation <simple-math>999 − <var>n</var></simple-math>. The nine’s complement (with the apostrophe) is equal to <simple-math>9<sup>3</sup> − <var>n</var> = 729 − <var>n</var></simple-math>, and is utterly irrelevant here.</aside><p>Notice that no matter what you subtract from 999, you <em>never</em> have to borrow. This means you can do the subtraction on each pair of digits without having to worry about any of the surrounding digits. We call the result of <simple-math>999 − <var>n</var></simple-math> the <keyword>nines complement</keyword> of <simple-math><var>n</var></simple-math>. Then we add 1 to get <simple-math>1000 − <var>n</var></simple-math>, but we already know how to add 1 to a number.</p><p>Doing it in binary is even easier because computing the <keyword>ones complement</keyword> is just a matter of flipping the bits. Adding 1 gives you the <keyword>two’s complement</keyword>, the negative of the number.</p><div class="centered-container"><ascii-figure>  1 1 1 1 1 1 1 1<br/>− 0 1 0 1 1 0 0 1<br/>—————————————————<br/>  1 0 1 0 0 1 1 0 = ones complement<br/>+               1<br/>—————————————————<br/>  1 0 1 0 0 1 1 1 = two’s complement</ascii-figure></div><h2>The most significant bit separates negative numbers from positive numbers</h2><aside>What about zero, you ask? Zero is signless because its complement in any base is always itself. Don’t believe me? Try it!</aside><p>Up until now, every 8 bit number has had two interpretations — a positive one, and a negative one. This is pretty silly, so we’ll define numbers with 1 as their most significant bit as negative, and numbers with 0 as their most significant bit as positive. For our purposes, zero rolls with the positives. We call this the <keyword>signed integer interpretation</keyword> of a binary value. The smallest byte value when viewed as a signed integer is <code>1000,0000</code>, or −128. The largest is <code>0111,1111</code>, or +127. Contrast with the unsigned integer interpretation which starts with <code>0000,0000</code>, or 0, and ends with <code>1111,1111</code>, or 255.</p><aside>Flipping the most significant bit of a signed byte adds 128 to its numeric value, mapping the range <simple-math>[−128, 128) to [0, 256)</simple-math>. Do you understand why?</aside><p>Defining negatives and positives this way makes comparisons easy because you can compare any two signed integers by flipping their most significant bit, and then comparing them as if they were unsigned integers.</p><p>Just like unsigned integers, signed integers can overflow. However, in terms of bit patterns, their overflow boundary occurs <a href="https://xkcd.com/571/" target="_blank">half a period out of phase</a> with that of unsigned integers.</p><div class="warning-container"><h2>Warning!</h2><p><warning>Unlike Swift, in some languages such as C and C++, signed integer overflow is undefined behavior.</warning></p></div><table class="data-table"><tr><td>Bit pattern</td> <td>Signed value</td> <td>Unsigned value</td> <td class="invisible"></td></tr>
<tr><td>0000,0000</td> <td>0</td> <td>0</td></tr>
<tr><td>0000,0001</td> <td>1</td> <td>1</td></tr>
<tr><td>0000,0010</td> <td>2</td> <td>2</td></tr>
<tr><td>0000,0011</td> <td>3</td> <td>3</td></tr>
<tr><td class="ellipsis"></td> <td class="ellipsis"></td> <td class="ellipsis"></td></tr>
<tr><td>0111,1110</td> <td>126</td> <td>126</td></tr>
<tr><td>0111,1111</td> <td>127</td> <td>127</td></tr>
<tr><td>1000,0000</td> <td><span style="background-color: rgba(255, 0, 50, 0.2);" class="highlight">−128</span></td> <td>128</td> <td class="annotation">← Signed overflow</td></tr>
<tr><td>1000,0001</td> <td>−127</td> <td>129</td></tr>
<tr><td>1000,0010</td> <td>−126</td> <td>130</td></tr>
<tr><td class="ellipsis"></td> <td class="ellipsis"></td> <td class="ellipsis"></td></tr>
<tr><td>1111,1101</td> <td>−3</td> <td>253</td></tr>
<tr><td>1111,1110</td> <td>−2</td> <td>254</td></tr>
<tr><td>1111,1111</td> <td>−1</td> <td>255</td></tr>
<tr><td>0000,0000</td> <td>0</td> <td><span style="background-color: rgba(255, 0, 50, 0.2);" class="highlight">0</span></td> <td class="annotation">← Unsigned overflow</td></tr></table><h2>Shifting multiplies and divides by the base</h2><p>Just as adding a zero to the end of a decimal number multiplies it by 10, adding a zero to the end of a binary number multiplies it by 2. Similarly, just as removing a zero from the end of a decimal number divides it by 10, removing a zero from the end of a binary number divides it by 2. This works even if the least significant digit is not a zero, in which case the quotient is given and the remainder discarded. In computing, this operation is called <keyword>shifting</keyword>. Because numbers are written from left to right in English, adding zeroes to the end effectively shifts all the existing digits left, so we call this operation a <keyword>left shift</keyword>. Removing digits from the end has the opposite effect, so we call that operation a <keyword>right shift</keyword>. The symbols for a left and right shift are ‘&lt;&lt;’ and ‘&gt;&gt;’, respectively.</p><p>Shifts can add or remove multiple digits to a number, in which case the factor it’s multiplied or divided by is the base raised to the power of the magnitude of the shift. As you might expect, shifting left by <simple-math><var>n</var></simple-math> is the same thing as shifting right by <simple-math><var>−n</var></simple-math>, and vice versa.</p><table class="data-table"><tr><td>Expression</td> <td>Bit pattern</td> <td>Unsigned value</td></tr>

<tr><td>13 &lt;&lt; 0</td> <td>0000,1101</td> <td>13</td></tr>
<tr><td>13 &lt;&lt; 1</td> <td>0001,1010</td> <td>26</td></tr>
<tr><td>13 &lt;&lt; 2</td> <td>0011,0100</td> <td>52</td></tr>
<tr><td>13 &lt;&lt; 3</td> <td>0110,1000</td> <td>104</td></tr>
<tr><td>13 &lt;&lt; 4</td> <td>1101,0000</td> <td>208</td></tr>

<tr><td class="invisible"></td></tr>

<tr><td>13 &gt;&gt; 0</td> <td>0000,1101</td> <td>13</td></tr>
<tr><td>13 &gt;&gt; 1</td> <td>0000,0110</td> <td>6</td></tr>
<tr><td>13 &gt;&gt; 2</td> <td>0000,0011</td> <td>3</td></tr>
<tr><td>13 &gt;&gt; 3</td> <td>0000,0001</td> <td>1</td></tr>
<tr><td>13 &gt;&gt; 4</td> <td>0000,0000</td> <td>0</td></tr></table><h2>Shifts can overflow</h2><p>Like addition and subtraction, left shifts can overflow.</p><table class="data-table"><tr><td>Expression</td> <td>Bit pattern</td> <td>Unsigned value</td></tr>

<tr><td>13 &lt;&lt; 4</td> <td>1101,0000</td> <td>208</td></tr>
<tr><td>13 &lt;&lt; 5</td> <td>1010,0000</td> <td>160</td></tr>
<tr><td>13 &lt;&lt; 6</td> <td>0100,0000</td> <td>64</td></tr>
<tr><td>13 &lt;&lt; 7</td> <td>1000,0000</td> <td>128</td></tr>
<tr><td>13 &lt;&lt; 8</td> <td>0000,0000</td> <td>0</td></tr></table><p>In fact, shifting an integer by an amount greater to or equal to its length will always result in 0, since all of its original bits will have been displaced with zeroes. This is called an <keyword>overshift</keyword>.</p><p>Right shifting signed integers involves some subtlety. Although replacing the removed digits on the right with zeroes on the left works fine for unsigned integers, weird things happen when you try to right shift signed integers.</p><table class="data-table"><tr><td>Expression</td> <td>Bit pattern</td> <td>Signed value</td></tr>

<tr><td>-89 &gt;&gt; 0</td> <td>1010,0111</td> <td>-89</td></tr>
<tr><td>-89 &gt;&gt; 1</td> <td>0101,0011</td> <td>+83</td></tr>
<tr><td>-89 &gt;&gt; 2</td> <td>0010,1001</td> <td>+41</td></tr>
<tr><td>-89 &gt;&gt; 3</td> <td>0001,0100</td> <td>+20</td></tr></table><p>The zeroes that appear on the left side of the bit pattern when the value is right shifted are called a <keyword>zero-extension</keyword>, or <keyword>ZEXT</keyword>. If we instead pad the left with copies of the sign bit, we get a more sensible result.</p><table class="data-table"><tr><td>Expression</td> <td>Bit pattern</td> <td>Signed value</td></tr>

<tr><td>-89 &gt;&gt; 0</td> <td>1010,0111</td> <td>-89</td></tr>
<tr><td>-89 &gt;&gt; 1</td> <td>1101,0011</td> <td>−45</td></tr>
<tr><td>-89 &gt;&gt; 2</td> <td>1110,1001</td> <td>−23</td></tr>
<tr><td>-89 &gt;&gt; 3</td> <td>1111,0100</td> <td>−12</td></tr></table><p>This kind of padding is called a <keyword>sign-extension</keyword>, or <keyword>SEXT</keyword>. (Yes, I know.) To differentiate between the two methods of right shifting, we call the zero-extending version a <keyword>logical right shift</keyword>, and the sign-extending version an <keyword>arithmetic right shift</keyword>. Logical right shifts are appropriate for unsigned values, while arithmetic right shifts are appropriate for signed values.</p><p>Like logical right shifts for unsigned integers, arithmetic right shifts round signed integers down (towards negative infinity.) So <simple-math>−89 &gt;&gt; 1</simple-math> is −45, not −44.</p><h2>Integer multiplication and division</h2><p>Binary multiplication is pretty straightfoward compared to decimal multiplication. The same elementary school algorithm works in binary, except we don’t even need to do any multiplication — multiplying two binary numbers is just a matter of adding up left-shifted versions of one of the factors, corresponding to the 1 bits in the other factor.</p><div class="centered-container"><ascii-figure><p>  0 0 0 1 0 1 1 1 = 23<br/>× 0 0 0 0 1 0 1 1 = 11<br/>——————————————————<br/>  0 0 0 1 0 1 1 1 = 23 &lt;&lt; 0<br/>  0 0 1 0 1 1 1   = 23 &lt;&lt; 1</p><p>+ 1 0 1 1 1       = 23 &lt;&lt; 3<br/>———————————————————<br/>  1 1 1 1 1 1 0 1 = 253</p></ascii-figure></div><p>As you can imagine, integer multiplication overflows pretty easily.</p><p>Multiplication is more complex to implement in hardware than addition is, but the multipliers in most processors are about as fast as the adders. Integer division, on the other hand, is far more complicated than either multiplication or addition, and is usually much slower than multiplication.</p><p>Integer dividers usually yield both the <keyword>quotient</keyword> and <keyword>remainder</keyword> at the same time. So the remainder operation (‘%’) is actually performed by the same circuit as the quotient operation (‘/’).</p><aside>Many Swift tutorials refer to <code>%</code> as the modulus operator. <em>This is wrong</em>. Modular division rounds towards negative infinity, so modulos are always positive. This means <simple-math>−7 mod 3</simple-math> is +2, not −1.</aside><p>Quotients and remainders are defined such that if <simple-math><var>a</var></simple-math> is the dividend, <simple-math><var>b</var></simple-math> is the divisor, <simple-math><var>q</var></simple-math> is the quotient, and <simple-math><var>r</var></simple-math> is the remainder, then <simple-math><var>a</var> ≡ <var>q</var> <var>b</var> + <var>r</var></simple-math>. Unlike an arithmetic right shift, an integer division always rounds towards zero. So <simple-math>−7 / 3</simple-math> is −2, not −3. This means the product <simple-math><var>q</var> <var>b</var></simple-math> and the remainder <simple-math><var>r</var></simple-math> always have the same sign as <simple-math><var>a</var></simple-math>. So <simple-math>−7 % 3</simple-math> is −1, not +2. It follows that <simple-math>−7 % −3</simple-math> is also −1.</p><h2>Boolean logic</h2><p>Several operations are native to binary and have no analogues in decimal. These operations are called <keyword>boolean operations</keyword>. The <keyword>not</keyword> (‘¬’), <keyword>and</keyword> (‘∧’), <keyword>inclusive or</keyword> (‘∨’), and <keyword>exclusive or</keyword> (‘⊻’) operations are the four that we usually consider “primary” boolean operators, though in truth, all boolean operators can be expressed in terms of just two of them: one of ∧ or ∨, combined with one of ¬ or ⊻. This property is called <keyword>logical completeness</keyword>.</p><p>Not is a <keyword>unary operator</keyword>, meaning it takes only one <keyword>operand</keyword>. Not is defined as the opposite of whatever its operand is. So ¬0 is 1, and ¬1 is 0.</p><aside>The word “binary” in this context just means “two” (as opposed to “one”.) It has nothing to do with base 2.</aside><p>And, inclusive or, and exclusive or are <keyword>binary operators</keyword>, meaning they take two operands. (Addition, subtraction, multiplication, and division are all also binary operations.)</p><p>And is defined as 1 if <em>both</em> operands are 1, and 0 otherwise. Inclusive or, which we usually just call “or”, is defined as 0 if <em>both</em> operands are 0, and 1 otherwise. This is the same as saying and is defined as 0 if <em>at least</em> one operand is 0, and or is defined as 1 if <em>at least</em> one operand is 1.</p><p>Exclusive or, which we usually abbreviate as <keyword>xor</keyword>, is defined as 1 if exactly <em>one</em> of the operands is 1. (This implies the other operand <em>must</em> be 0.) Anything xored with itself yields 0.</p><p>And, or, and xor are all commutative. So <simple-math><var>p</var> ∧ <var>q</var> ≡ <var>q</var> ∧ <var>p</var></simple-math>, <simple-math><var>p</var> ∨ <var>q</var> ≡ <var>q</var> ∨ <var>p</var></simple-math>, and <simple-math><var>p</var> ⊻ <var>q</var> ≡ <var>q</var> ⊻ <var>p</var></simple-math>.</p><h2>Bitwise and logical boolean operations</h2><p>Boolean operations can be performed on data values on a <keyword>bitwise</keyword> basis, applying the operator to each bit (or pair of bits) in the operand (or operands) independently.</p><div class="centered-container"><ascii-figure>¬ 0 1 0 1 1 0 0 1<br/>—————————————————<br/>  1 0 1 0 0 1 1 0</ascii-figure></div><div class="centered-container"><ascii-figure>  0 1 0 1 1 0 0 1<br/>∧ 0 0 0 1 0 1 1 0<br/>—————————————————<br/>  0 0 0 1 0 0 0 0</ascii-figure></div><div class="centered-container"><ascii-figure>  0 1 0 1 1 0 0 1<br/>∨ 0 0 0 1 0 1 1 0<br/>—————————————————<br/>  0 1 0 1 1 1 1 1</ascii-figure></div><div class="centered-container"><ascii-figure>  0 1 0 1 1 0 0 1<br/>⊻ 0 0 0 1 0 1 1 0<br/>—————————————————<br/>  0 1 0 0 1 1 1 1</ascii-figure></div><p>Bitwise boolean operations generally have no arithmetic meaning and are mainly used to manipulate bits within a data value. An exception is the ∧ operator, which can be used to take the modulo of a number if the modulus is a power of two. <code>0101,1001 ∧ 0000,1111 = 0000,1001</code> is equivalent to <simple-math>89 mod 16 = 9</simple-math>. Arithmetic right shift and and can be thought of as special cases of flooring division (integer division rounding towards negative infinity) and modulo.</p><p>Boolean operations can also be performed on integers as whole units, treating all nonzero integers as being in an <keyword>equivalence class</keyword> with 1. Boolean operations performed in this way are called <keyword>logical boolean operations</keyword>, to contrast them with bitwise boolean operations. A logical operation doesn’t always give the same result as its corresponding bitwise operation on the same inputs. <code>0101,0101 ∧ 1010,1010</code> is 1 with a logical and (since both operands are nonzero), but 0 with a bitwise and (since no two corresponding bits are both 1.)</p><p>Only ∧, ∨, and ¬ have well-defined logical forms. Nonequality (‘≠’) is usually taken as the logical version of ⊻, though there are alternative ways of generalizing ⊻ to the logical domain.</p>
        </div>
    </div>
</body>
</html>